{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "df = pd.ExcelFile(\"D:\\\\R dir\\\\PCA_Data\\\\Tamilnadu_PCA_2011.xlsx\")\n",
      "df = df.parse(\"Sheet1\",index_col=None, na_values=['NA'])\n",
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>State</th>\n",
        "      <th>District</th>\n",
        "      <th>Subdistt</th>\n",
        "      <th>Town/Village</th>\n",
        "      <th>Ward</th>\n",
        "      <th>EB</th>\n",
        "      <th>Level</th>\n",
        "      <th>Name</th>\n",
        "      <th>TRU</th>\n",
        "      <th>No_HH</th>\n",
        "      <th>TOT_P</th>\n",
        "      <th>TOT_M</th>\n",
        "      <th>TOT_F</th>\n",
        "      <th>P_06</th>\n",
        "      <th>M_06</th>\n",
        "      <th>F_06</th>\n",
        "      <th>P_SC</th>\n",
        "      <th>M_SC</th>\n",
        "      <th>F_SC</th>\n",
        "      <th>P_ST</th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 33</td>\n",
        "      <td> 602</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> DISTRICT</td>\n",
        "      <td> Thiruvallur</td>\n",
        "      <td> Total</td>\n",
        "      <td>  946949</td>\n",
        "      <td> 3728104</td>\n",
        "      <td> 1876062</td>\n",
        "      <td> 1852042</td>\n",
        "      <td> 405669</td>\n",
        "      <td> 208449</td>\n",
        "      <td> 197220</td>\n",
        "      <td> 821646</td>\n",
        "      <td> 410526</td>\n",
        "      <td> 411120</td>\n",
        "      <td> 47243</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 33</td>\n",
        "      <td> 602</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> DISTRICT</td>\n",
        "      <td> Thiruvallur</td>\n",
        "      <td> Rural</td>\n",
        "      <td>  331697</td>\n",
        "      <td> 1299709</td>\n",
        "      <td>  650462</td>\n",
        "      <td>  649247</td>\n",
        "      <td> 141907</td>\n",
        "      <td>  72902</td>\n",
        "      <td>  69005</td>\n",
        "      <td> 451999</td>\n",
        "      <td> 225349</td>\n",
        "      <td> 226650</td>\n",
        "      <td> 35044</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 33</td>\n",
        "      <td> 602</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> DISTRICT</td>\n",
        "      <td> Thiruvallur</td>\n",
        "      <td> Urban</td>\n",
        "      <td>  615252</td>\n",
        "      <td> 2428395</td>\n",
        "      <td> 1225600</td>\n",
        "      <td> 1202795</td>\n",
        "      <td> 263762</td>\n",
        "      <td> 135547</td>\n",
        "      <td> 128215</td>\n",
        "      <td> 369647</td>\n",
        "      <td> 185177</td>\n",
        "      <td> 184470</td>\n",
        "      <td> 12199</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 33</td>\n",
        "      <td> 603</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> DISTRICT</td>\n",
        "      <td>     Chennai</td>\n",
        "      <td> Total</td>\n",
        "      <td> 1154982</td>\n",
        "      <td> 4646732</td>\n",
        "      <td> 2335844</td>\n",
        "      <td> 2310888</td>\n",
        "      <td> 459324</td>\n",
        "      <td> 235519</td>\n",
        "      <td> 223805</td>\n",
        "      <td> 779667</td>\n",
        "      <td> 389001</td>\n",
        "      <td> 390666</td>\n",
        "      <td> 10061</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 33</td>\n",
        "      <td> 603</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> DISTRICT</td>\n",
        "      <td>     Chennai</td>\n",
        "      <td> Rural</td>\n",
        "      <td>       0</td>\n",
        "      <td>       0</td>\n",
        "      <td>       0</td>\n",
        "      <td>       0</td>\n",
        "      <td>      0</td>\n",
        "      <td>      0</td>\n",
        "      <td>      0</td>\n",
        "      <td>      0</td>\n",
        "      <td>      0</td>\n",
        "      <td>      0</td>\n",
        "      <td>     0</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 94 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "   State  District  Subdistt  Town/Village  Ward  EB     Level         Name  \\\n",
        "0     33       602         0             0     0   0  DISTRICT  Thiruvallur   \n",
        "1     33       602         0             0     0   0  DISTRICT  Thiruvallur   \n",
        "2     33       602         0             0     0   0  DISTRICT  Thiruvallur   \n",
        "3     33       603         0             0     0   0  DISTRICT      Chennai   \n",
        "4     33       603         0             0     0   0  DISTRICT      Chennai   \n",
        "\n",
        "     TRU    No_HH    TOT_P    TOT_M    TOT_F    P_06    M_06    F_06    P_SC  \\\n",
        "0  Total   946949  3728104  1876062  1852042  405669  208449  197220  821646   \n",
        "1  Rural   331697  1299709   650462   649247  141907   72902   69005  451999   \n",
        "2  Urban   615252  2428395  1225600  1202795  263762  135547  128215  369647   \n",
        "3  Total  1154982  4646732  2335844  2310888  459324  235519  223805  779667   \n",
        "4  Rural        0        0        0        0       0       0       0       0   \n",
        "\n",
        "     M_SC    F_SC   P_ST      \n",
        "0  410526  411120  47243 ...  \n",
        "1  225349  226650  35044 ...  \n",
        "2  185177  184470  12199 ...  \n",
        "3  389001  390666  10061 ...  \n",
        "4       0       0      0 ...  \n",
        "\n",
        "[5 rows x 94 columns]"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.columns  = df.columns.map(lambda x: x.lower())\n",
      "#print df.columns\n",
      "\n",
      "split_col_name = df.columns.map(lambda x: x.split(' '))\n",
      "print df.columns\n",
      "print df.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Index([u'state', u'district', u'subdistt', u'town/village', u'ward', u'eb', u'level', u'name', u'tru', u'no_hh', u'tot_p', u'tot_m', u'tot_f', u'p_06', u'm_06', u'f_06', u'p_sc', u'm_sc', u'f_sc', u'p_st', u'm_st', u'f_st', u'p_lit', u'm_lit', u'f_lit', u'p_ill', u'm_ill', u'f_ill', u'tot_work_p', u'tot_work_m', u'tot_work_f', u'mainwork_p', u'mainwork_m', u'mainwork_f', u'main_cl_p', u'main_cl_m', u'main_cl_f', u'main_al_p', u'main_al_m', u'main_al_f', u'main_hh_p', u'main_hh_m', u'main_hh_f', u'main_ot_p', u'main_ot_m', u'main_ot_f', u'margwork_p', u'margwork_m', u'margwork_f', u'marg_cl_p', u'marg_cl_m', u'marg_cl_f', u'marg_al_p', u'marg_al_m', u'marg_al_f', u'marg_hh_p', u'marg_hh_m', u'marg_hh_f', u'marg_ot_p', u'marg_ot_m', u'marg_ot_f', u'margwork_3_6_p', u'margwork_3_6_m', u'margwork_3_6_f', u'marg_cl_3_6_p', u'marg_cl_3_6_m', u'marg_cl_3_6_f', u'marg_al_3_6_p', u'marg_al_3_6_m', u'marg_al_3_6_f', u'marg_hh_3_6_p', u'marg_hh_3_6_m', u'marg_hh_3_6_f', u'marg_ot_3_6_p', u'marg_ot_3_6_m', u'marg_ot_3_6_f', u'margwork_0_3_p', u'margwork_0_3_m', u'margwork_0_3_f', u'marg_cl_0_3_p', u'marg_cl_0_3_m', u'marg_cl_0_3_f', u'marg_al_0_3_p', u'marg_al_0_3_m', u'marg_al_0_3_f', u'marg_hh_0_3_p', u'marg_hh_0_3_m', u'marg_hh_0_3_f', u'marg_ot_0_3_p', u'marg_ot_0_3_m', u'marg_ot_0_3_f', u'non_work_p', u'non_work_m', u'non_work_f'], dtype='object')\n",
        "(31052, 94)\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test = df[30802:31052]\n",
      "train = df[0:30802]\n",
      "colmn_req_X = [10]\n",
      "X_train = train[colmn_req_X]\n",
      "print X_train.shape\n",
      "#print test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(30802, 1)\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "colmn_req_Y = [9]\n",
      "Y_train = train[colmn_req_Y]\n",
      "print Y_train.shape\n",
      "#print train[colmn_req_Y]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(30802, 1)\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn\n",
      "from sklearn import linear_model\n",
      "reg1 = linear_model.LinearRegression()\n",
      "reg1.fit(X_train, Y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "LinearRegression(copy_X=True, fit_intercept=True, normalize=False)"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print reg1.coef_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.25456324]]\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test = df[:250]\n",
      "#print test.shape\n",
      "X_test = test[colmn_req_X]\n",
      "Y_test = test[colmn_req_Y]\n",
      "error = np.mean((reg1.predict(X_test) - Y_test) ** 2)\n",
      "print error\n",
      "score = reg1.score(X_test, Y_test)\n",
      "print score\n",
      "print X_test.shape\n",
      "print Y_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "no_hh    2.754908e+08\n",
        "dtype: float64\n",
        "0.995687180719\n",
        "(250, 1)\n",
        "(250, 1)\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "plt.clf()\n",
      "plt.close()\n",
      "plt.scatter(X_test, Y_test, color = \"black\")\n",
      "plt.plot(X_test, reg1.predict(X_test), color='blue', linewidth=3)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Trying Multiple Linear Regression \n",
      "test = df[30802:31052]\n",
      "train = df[0:30802]\n",
      "Yf = np.linspace(10,93,84)\n",
      "Yf = Yf.astype(int)\n",
      "#colmn_req = [Yf]\n",
      "X_train2 = train[Yf]\n",
      "Y_train2 = train[colmn_req_Y]\n",
      "print X_train2.shape\n",
      "print Y_train2.shape\n",
      "\n",
      "#print X_train2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(30802, 84)\n",
        "(30802, 1)\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reg2 = linear_model.LinearRegression()\n",
      "y = reg2.fit(X_train2, Y_train2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_test2 = test[Yf]\n",
      "Y_test2 = test[colmn_req_Y]\n",
      "#print reg2.predict(X_test2).astype(int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print reg2.coef_\n",
      "print reg2.intercept_\n",
      "#error = error = np.mean((reg1.predict(X_test) - Y_test) ** 2)\n",
      "#print error\n",
      "score2 = reg2.score(X_test2, Y_test2)\n",
      "print score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ -2.11607551e+11   3.86311030e+11   3.68211176e+11  -3.16747577e+10\n",
        "    3.16747577e+10   3.16747577e+10  -1.44248945e+10   1.44248945e+10\n",
        "    1.44248945e+10  -1.03656528e+09   1.03656528e+09   1.03656528e+09\n",
        "   -1.34308925e+11  -6.11948085e+09   9.59231096e+09  -8.77789830e+10\n",
        "   -5.26494230e+10  -3.69376312e+10  -7.09858146e+10  -2.20164112e+09\n",
        "    2.00997731e+10   2.98731434e+10   1.45639688e+10  -5.30626681e+09\n",
        "    2.20919000e+09  -7.73391892e+09  -7.77703565e+09   5.73262293e+08\n",
        "   -6.09799121e+09  -6.14110794e+09  -4.42642790e+09  -1.09830102e+09\n",
        "   -1.14141775e+09   3.78080767e+09  -9.30553658e+09  -9.34865332e+09\n",
        "    2.55177638e+10   1.33227585e+10  -3.22775669e+09   1.15298246e+09\n",
        "    5.53419690e+07   4.56060839e+08   2.08435719e+09  -8.23873220e+08\n",
        "   -1.54743797e+09   1.58619874e+09   3.57892373e+08   3.52518093e+08\n",
        "   -7.85253172e+08  -1.00421377e+09  -2.75188371e+08  -7.80287741e+09\n",
        "    4.28771221e+09   3.78962490e+08   1.69012899e+09   6.88572739e+08\n",
        "    8.33766446e+08   3.42191311e+09  -1.09537092e+09   1.74106412e+08\n",
        "    1.05595469e+09   5.86980358e+08   1.13826721e+09   1.55423320e+09\n",
        "    3.82225991e+09   3.63914708e+09  -5.26571584e+08   6.85350566e+08\n",
        "   -2.23399500e+09  -1.12825117e+09  -1.66991275e+08  -1.01120173e+09\n",
        "   -9.64683457e+08  -3.82718550e+08  -1.02645353e+08  -1.68251521e+09\n",
        "   -3.48493957e+08  -7.86611224e+08   1.39654742e+09   3.06001499e+08\n",
        "   -8.66515471e+08   1.66897521e+10  -5.09648247e+10  -4.85767628e+10]]\n",
        "[ 28.33604555]\n",
        "0.995687180719\n"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Trying the feature Selection\n",
      "\n",
      "def f_regression(X,Y):\n",
      "   import sklearn\n",
      "   return sklearn.feature_selection.f_regression(X,Y,center=False) \n",
      "\n",
      "from sklearn.feature_selection import SelectKBest\n",
      "featureSelector = SelectKBest(score_func=f_regression,k=10)\n",
      "featureSelector.fit(X_train2,Y_train2)\n",
      "print [1+zero_based_index for zero_based_index in list(featureSelector.get_support(indices=True))]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[1, 2, 3, 13, 14, 19, 20, 22, 23, 83]\n"
       ]
      }
     ],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d = sklearn.feature_selection.univariate_selection.f_regression(X_train2, Y_train2, center=True)\n",
      "print d[0].astype(int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 9648484  9137486  9652628  2175006  2096891  2235031   251568   249693\n",
        "   253179    18092    18052    18128  2958033  5006943  1731003   438826\n",
        "   476118   408252  2333369 15996065   317305  2820772  9856790   310112\n",
        "    29096    31330    23693    43449    45297    39795    34925    59138\n",
        "    14627   261452   262860   214959   102235   118389    84348    24350\n",
        "    23503    24774    24878    25389    24019    73328    89519    59199\n",
        "   230136   213023   238521   106011   120335    88815    24574    23679\n",
        "    25020    25160    25635    24239    72286    86030    57759   223523\n",
        "   215296   219439    78128    97517    61015    20269    19709    20191\n",
        "    22473    22701    22006    71126    87702    58542   184457   157292\n",
        "   186846  2161280  3155746  1376868]\n"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Ridge Regression\n",
      "\n",
      "reg3 = linear_model.Ridge (alpha = .5)\n",
      "reg3.fit (X_train2, Y_train2) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 73,
       "text": [
        "Ridge(alpha=0.5, copy_X=True, fit_intercept=True, max_iter=None,\n",
        "   normalize=False, solver='auto', tol=0.001)"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred3 = reg3.predict(X_test2)\n",
      "#print pred3.astype(int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print reg3.coef_\n",
      "print reg3.intercept_\n",
      "print reg3.score(X_test2, Y_test2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ -9.50343492e-01  -1.10429449e+00  -1.22586940e+00  -2.27429948e-01\n",
        "    1.58346310e+00  -1.87895240e+00  -5.88441912e-02   2.48899798e+00\n",
        "   -2.43866896e+00  -8.34930238e-03  -3.60656293e+00   3.58877266e+00\n",
        "    1.35154151e+00  -7.33628005e-01  -2.72785725e-02   6.21659544e-01\n",
        "   -1.46097659e-01   6.31372772e-01   1.13416822e+00   3.40398061e-01\n",
        "   -5.35055682e-02   8.34352851e-01  -6.32708900e-01  -1.26958245e-01\n",
        "    3.52309336e-02  -4.52219154e-01   4.34772810e-01   9.11221374e-03\n",
        "    4.37442356e-01  -5.02596450e-01  -1.69195407e-03  -3.43777464e-02\n",
        "    2.80371664e-02  -5.83398541e-03   6.83098734e-04   7.40276288e-02\n",
        "    4.95357513e-02   1.07542583e-01   4.37749207e-02   9.94119289e-01\n",
        "    4.63138763e+00  -3.63471212e+00  -3.65177265e-01  -1.99773011e+00\n",
        "    1.68148748e+00  -1.03304829e+00  -2.75013657e+00   1.70799130e+00\n",
        "    5.45489688e-01   2.18269783e-01   3.81928807e-01   1.14956457e-01\n",
        "    1.64148357e+00  -1.47343974e+00  -1.59808142e+00  -4.45037540e+00\n",
        "    2.84978563e+00   3.73288295e-01   1.09640225e+00  -6.69443457e-01\n",
        "    2.20273653e+00   5.83872050e+00  -3.63783156e+00  -9.04418036e-01\n",
        "   -9.85662985e-01   5.15287059e-03   8.95638797e-02  -1.50171536e+00\n",
        "    1.56733660e+00   2.59246774e+00   9.08209349e+00  -6.49009859e+00\n",
        "   -7.31202103e-01  -3.07398341e+00   2.33264370e+00  -3.24566093e+00\n",
        "   -8.58349700e+00   5.34576236e+00   1.46605368e+00   1.08555252e+00\n",
        "    3.87061199e-01   1.28026721e+00  -2.90533766e-01   1.86269048e-01]]\n",
        "[ 7.45941844]\n",
        "0.999430477088\n"
       ]
      }
     ],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Lasso Regression\n",
      "\n",
      "reg4 = linear_model.Lasso(alpha = 0.001)\n",
      "reg4.fit(X_train2, Y_train2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 76,
       "text": [
        "Lasso(alpha=0.001, copy_X=True, fit_intercept=True, max_iter=1000,\n",
        "   normalize=False, positive=False, precompute='auto', tol=0.0001,\n",
        "   warm_start=False)"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred4 = reg4.predict(X_test2)\n",
      "#print pred4.astype(int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print reg4.coef_\n",
      "print reg4.intercept_\n",
      "print reg4.score(X_test2, Y_test2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  2.79710770e-01   4.06847154e-03  -8.21450731e-03  -4.28611612e-01\n",
        "   2.61562715e-02  -5.70417564e-02  -3.30109166e-02   5.41336146e-02\n",
        "  -1.07855826e-01  -2.16914668e-01  -3.51487586e-01   7.26259132e-01\n",
        "   8.20332586e-02   5.26407490e-03  -1.30607133e-02  -1.34283888e-03\n",
        "   1.17758277e-02  -1.31984203e-02   1.23806358e-01  -4.89989392e-03\n",
        "   2.77620850e-02  -4.77269488e-03  -7.48446871e-03   5.23325773e-02\n",
        "  -2.97436077e-01  -1.83396174e-01   8.91179383e-01   1.70764608e-01\n",
        "   2.70560426e-01  -6.05572919e-01   6.33492224e-02  -7.15446610e-02\n",
        "   5.33021205e-02  -2.31043124e-02  -1.69972809e-02   2.52510318e-01\n",
        "  -1.40447700e-01   3.39092861e-02  -6.66917805e-02   3.23029910e-02\n",
        "   3.88331999e-01  -1.14772908e+00   1.54845035e-01   1.66723184e-01\n",
        "  -2.21188599e-01  -2.65514260e-01   2.70517053e+00  -1.58056238e+00\n",
        "  -1.04342716e-01   1.82600174e-02  -6.38805282e-02   5.12142287e-02\n",
        "   5.96374927e-02  -1.21943273e-01  -1.97934107e-01   4.29116494e-01\n",
        "  -1.31413208e+00   2.34452363e-01   2.94758859e-01  -4.06027190e-01\n",
        "   1.06202091e+00   5.36551672e+00  -3.16643325e+00  -1.89594813e-01\n",
        "   2.91097365e-03  -1.01708953e-02   4.73625737e-01  -2.69731643e-01\n",
        "   4.23252032e-01   7.65266360e+00   3.60664828e+00  -8.03581603e+00\n",
        "  -1.95425563e+00  -3.44636899e+00   3.66297516e+00  -3.99606303e+00\n",
        "  -1.73556761e+01   9.68510313e+00   2.33260167e+00   6.80445099e-01\n",
        "  -2.27858055e+00  -1.70646381e-01  -1.34519865e-01   1.21307746e-01]\n",
        "[ 7.3768683]\n",
        "0.999460188695\n"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#LARS Lasso Regression\n",
      "\n",
      "reg5 = linear_model.LassoLars(alpha=.1)\n",
      "reg5.fit(X_test2, Y_test2) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 80,
       "text": [
        "LassoLars(alpha=0.1, copy_X=True, eps=2.2204460492503131e-16,\n",
        "     fit_intercept=True, fit_path=True, max_iter=500, normalize=True,\n",
        "     precompute='auto', verbose=False)"
       ]
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print reg5.coef_\n",
      "print reg5.intercept_\n",
      "print reg5.score(X_test2, Y_test2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.06642159  0.          0.23702027  0.          0.          0.          0.\n",
        "  0.0231267   0.          0.         -0.0076198   0.          0.          0.\n",
        "  0.          0.          0.          0.          0.          0.26686679\n",
        "  0.          0.01883529  0.          0.          0.          0.03766536\n",
        "  0.          0.          0.          0.          0.          0.\n",
        "  0.34573427  0.          0.00402884  0.          0.          0.          0.\n",
        "  0.          0.          0.          0.          0.          0.          0.\n",
        "  0.          0.          0.          0.          0.          0.\n",
        "  0.02127937  0.          0.          0.          0.          0.          0.\n",
        "  0.          0.          0.          0.          0.          0.10561092\n",
        "  0.          0.          0.          0.          0.          0.          0.\n",
        "  0.          0.          0.48009257  0.          0.          0.          0.\n",
        "  0.          0.          0.          0.          0.        ]\n",
        "[ 0.24801811]\n",
        "0.999965641846\n"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print type(reg5.coef_)\n",
      "print reg5.coef_.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<type 'numpy.ndarray'>\n",
        "(84,)\n"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy import sparse\n",
      "X_csr = sparse.csr_matrix(reg5.coef_)\n",
      "print X_csr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  (0, 0)\t0.0664215939886\n",
        "  (0, 2)\t0.237020266763\n",
        "  (0, 7)\t0.0231266954111\n",
        "  (0, 10)\t-0.00761979847267\n",
        "  (0, 19)\t0.266866785529\n",
        "  (0, 21)\t0.0188352858399\n",
        "  (0, 25)\t0.0376653608381\n",
        "  (0, 32)\t0.345734272748\n",
        "  (0, 34)\t0.0040288358813\n",
        "  (0, 52)\t0.0212793702182\n",
        "  (0, 64)\t0.105610915908\n",
        "  (0, 74)\t0.480092568611\n"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred5 = reg5.predict(X_test2)\n",
      "print pred5.astype(int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  652   458    91   379   515   452   405   183   573   608   474 11932\n",
        "   630   438   481   831   388   473   851   866   282   656   962   542\n",
        "   718  1263   834   416   469   828  8214  8214  1752  1752  2380  2380\n",
        " 67956 38358 29598   225   387  1710   530   837   839  1348   881   573\n",
        "   425   924  3588  2485   656  1370  2525   374   468   860   137   399\n",
        "  1337   743   516  1398   231    37   173   684   478   173  1570   376\n",
        "   424  1387   245   230   152   261  1623   111   124   327   867  1129\n",
        "  1268   287   621    20    14 17185   369   590   765   496   505   839\n",
        "   658   532   226   452   177   454   390   982   574   312   295   295\n",
        "   560   301   471   316   900   626   256   463   401  1071   664   490\n",
        "   680   225   842  1661    95    65    39    59    39    55    63   231\n",
        "   272    87   201   302    64    60    26  4751  4751  4602  4602  1398\n",
        "  1398 52739 38256 14484   586   971   904   202   900  1090   458   982\n",
        "  1426   708  1371   915   635   756  2684  1129  1780  1560  1465  2311\n",
        "   713  1070   891   582  1204   785   476   157  2053  1762   936  1318\n",
        "   741  1915   809  1723   108   113   109   124   127   160   109   102\n",
        "   112   113    95    86   104   147   109  5820   399   293   460   352\n",
        "   440   177   578   371   279   240   301   522   270   208   110   260\n",
        "   359   195  3930   283   252   174   261   318   342   191   229   247\n",
        "   340   224   298   328   207   233  3010   328   200   138   169    96\n",
        "   221   313   296   264   144   106    81   131   204   315]\n"
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.clf()\n",
      "plt.close()\n",
      "from mpl_toolkits.mplot3d import Axes3D\n",
      "import statsmodels.api as sm\n",
      "X = df[['tot_m', 'tot_f']]\n",
      "y = df['no_hh']\n",
      "\n",
      "## fit a OLS model with intercept on TV and Radio\n",
      "X = sm.add_constant(X)\n",
      "est = sm.GLS(y, X).fit()\n",
      "\n",
      "## Create the 3d plot -- skip reading this\n",
      "# TV/Radio grid for 3d plot\n",
      "xx1, xx2= np.meshgrid(np.linspace(X.tot_m.min(), X.tot_m.max(), 100), \n",
      "                       np.linspace(X.tot_f.min(), X.tot_f.max(), 100),\n",
      "                       )\n",
      "# plot the hyperplane by evaluating the parameters on the grid\n",
      "Z = est.params[0] + est.params[1] * xx1 + est.params[2] * xx2\n",
      "\n",
      "# create matplotlib 3d axes\n",
      "fig = plt.figure(figsize=(12, 8))\n",
      "ax = Axes3D(fig, azim=-115, elev=15)\n",
      "\n",
      "# plot hyperplane\n",
      "surf = ax.plot_surface(xx1, xx2, Z, cmap=plt.cm.RdBu_r, alpha=0.6, linewidth=0)\n",
      "\n",
      "# plot data points - points over the HP are white, points below are black\n",
      "resid = y - est.predict(X)\n",
      "ax.scatter(X[resid >= 0].tot_m, X[resid >= 0].tot_f, y[resid >= 0], color='red', alpha=1.0, facecolor='white')\n",
      "ax.scatter(X[resid < 0].tot_m, X[resid < 0].tot_f, y[resid < 0], color='black', alpha=1.0, facecolor='white')\n",
      "\n",
      "# set axis labels\n",
      "ax.set_xlabel('Male Population')\n",
      "ax.set_ylabel('Female population')\n",
      "ax.set_zlabel('No. of households')\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "est.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table class=\"simpletable\">\n",
        "<caption>GLS Regression Results</caption>\n",
        "<tr>\n",
        "  <th>Dep. Variable:</th>          <td>no_hh</td>      <th>  R-squared:         </th>  <td>   0.997</td>  \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Model:</th>                   <td>GLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.997</td>  \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>4.895e+06</td> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Date:</th>             <td>Tue, 20 May 2014</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Time:</th>                 <td>11:36:47</td>     <th>  Log-Likelihood:    </th> <td>-2.8347e+05</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>No. Observations:</th>      <td> 31052</td>      <th>  AIC:               </th>  <td>5.669e+05</td> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Df Residuals:</th>          <td> 31049</td>      <th>  BIC:               </th>  <td>5.670e+05</td> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>      <td> </td>     \n",
        "</tr>\n",
        "</table>\n",
        "<table class=\"simpletable\">\n",
        "<tr>\n",
        "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>const</th> <td>   35.8203</td> <td>   12.739</td> <td>    2.812</td> <td> 0.005</td> <td>   10.851    60.789</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>tot_m</th> <td>    0.1248</td> <td>    0.009</td> <td>   14.484</td> <td> 0.000</td> <td>    0.108     0.142</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>tot_f</th> <td>    0.3852</td> <td>    0.009</td> <td>   44.409</td> <td> 0.000</td> <td>    0.368     0.402</td>\n",
        "</tr>\n",
        "</table>\n",
        "<table class=\"simpletable\">\n",
        "<tr>\n",
        "  <th>Omnibus:</th>       <td>35875.931</td> <th>  Durbin-Watson:     </th>   <td>   0.888</td>   \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>609300375.575</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Skew:</th>           <td> 4.486</td>   <th>  Prob(JB):          </th>   <td>    0.00</td>   \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Kurtosis:</th>       <td>689.182</td>  <th>  Cond. No.          </th>   <td>1.11e+05</td>   \n",
        "</tr>\n",
        "</table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 60,
       "text": [
        "<class 'statsmodels.iolib.summary.Summary'>\n",
        "\"\"\"\n",
        "                            GLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:                  no_hh   R-squared:                       0.997\n",
        "Model:                            GLS   Adj. R-squared:                  0.997\n",
        "Method:                 Least Squares   F-statistic:                 4.895e+06\n",
        "Date:                Tue, 20 May 2014   Prob (F-statistic):               0.00\n",
        "Time:                        11:36:47   Log-Likelihood:            -2.8347e+05\n",
        "No. Observations:               31052   AIC:                         5.669e+05\n",
        "Df Residuals:                   31049   BIC:                         5.670e+05\n",
        "Df Model:                           2                                         \n",
        "==============================================================================\n",
        "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
        "------------------------------------------------------------------------------\n",
        "const         35.8203     12.739      2.812      0.005        10.851    60.789\n",
        "tot_m          0.1248      0.009     14.484      0.000         0.108     0.142\n",
        "tot_f          0.3852      0.009     44.409      0.000         0.368     0.402\n",
        "==============================================================================\n",
        "Omnibus:                    35875.931   Durbin-Watson:                   0.888\n",
        "Prob(Omnibus):                  0.000   Jarque-Bera (JB):        609300375.575\n",
        "Skew:                           4.486   Prob(JB):                         0.00\n",
        "Kurtosis:                     689.182   Cond. No.                     1.11e+05\n",
        "==============================================================================\n",
        "\n",
        "Warnings:\n",
        "[1] The condition number is large, 1.11e+05. This might indicate that there are\n",
        "strong multicollinearity or other numerical problems.\n",
        "\"\"\""
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import statsmodels.formula.api as smf\n",
      "est = smf.gls(formula='no_hh ~ tot_m + tot_f + p_06 + m_06', data=df).fit()\n",
      "est.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table class=\"simpletable\">\n",
        "<caption>GLS Regression Results</caption>\n",
        "<tr>\n",
        "  <th>Dep. Variable:</th>          <td>no_hh</td>      <th>  R-squared:         </th>  <td>   0.998</td>  \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Model:</th>                   <td>GLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.998</td>  \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>4.925e+06</td> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Date:</th>             <td>Tue, 20 May 2014</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Time:</th>                 <td>12:17:26</td>     <th>  Log-Likelihood:    </th> <td>-2.7264e+05</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>No. Observations:</th>      <td> 31052</td>      <th>  AIC:               </th>  <td>5.453e+05</td> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Df Residuals:</th>          <td> 31047</td>      <th>  BIC:               </th>  <td>5.453e+05</td> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>      <td> </td>     \n",
        "</tr>\n",
        "</table>\n",
        "<table class=\"simpletable\">\n",
        "<tr>\n",
        "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Intercept</th> <td>   34.9018</td> <td>    8.989</td> <td>    3.883</td> <td> 0.000</td> <td>   17.284    52.520</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>tot_m</th>     <td>    0.4644</td> <td>    0.007</td> <td>   62.922</td> <td> 0.000</td> <td>    0.450     0.479</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>tot_f</th>     <td>    0.3308</td> <td>    0.007</td> <td>   45.102</td> <td> 0.000</td> <td>    0.316     0.345</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>p_06</th>      <td>   -1.1242</td> <td>    0.077</td> <td>  -14.652</td> <td> 0.000</td> <td>   -1.275    -0.974</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>m_06</th>      <td>   -0.5179</td> <td>    0.146</td> <td>   -3.549</td> <td> 0.000</td> <td>   -0.804    -0.232</td>\n",
        "</tr>\n",
        "</table>\n",
        "<table class=\"simpletable\">\n",
        "<tr>\n",
        "  <th>Omnibus:</th>       <td>16949.644</td> <th>  Durbin-Watson:     </th>   <td>   1.312</td>   \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>663009654.831</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Skew:</th>           <td> 0.457</td>   <th>  Prob(JB):          </th>   <td>    0.00</td>   \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Kurtosis:</th>       <td>718.847</td>  <th>  Cond. No.          </th>   <td>1.13e+05</td>   \n",
        "</tr>\n",
        "</table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 68,
       "text": [
        "<class 'statsmodels.iolib.summary.Summary'>\n",
        "\"\"\"\n",
        "                            GLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:                  no_hh   R-squared:                       0.998\n",
        "Model:                            GLS   Adj. R-squared:                  0.998\n",
        "Method:                 Least Squares   F-statistic:                 4.925e+06\n",
        "Date:                Tue, 20 May 2014   Prob (F-statistic):               0.00\n",
        "Time:                        12:17:26   Log-Likelihood:            -2.7264e+05\n",
        "No. Observations:               31052   AIC:                         5.453e+05\n",
        "Df Residuals:                   31047   BIC:                         5.453e+05\n",
        "Df Model:                           4                                         \n",
        "==============================================================================\n",
        "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
        "------------------------------------------------------------------------------\n",
        "Intercept     34.9018      8.989      3.883      0.000        17.284    52.520\n",
        "tot_m          0.4644      0.007     62.922      0.000         0.450     0.479\n",
        "tot_f          0.3308      0.007     45.102      0.000         0.316     0.345\n",
        "p_06          -1.1242      0.077    -14.652      0.000        -1.275    -0.974\n",
        "m_06          -0.5179      0.146     -3.549      0.000        -0.804    -0.232\n",
        "==============================================================================\n",
        "Omnibus:                    16949.644   Durbin-Watson:                   1.312\n",
        "Prob(Omnibus):                  0.000   Jarque-Bera (JB):        663009654.831\n",
        "Skew:                           0.457   Prob(JB):                         0.00\n",
        "Kurtosis:                     718.847   Cond. No.                     1.13e+05\n",
        "==============================================================================\n",
        "\n",
        "Warnings:\n",
        "[1] The condition number is large, 1.13e+05. This might indicate that there are\n",
        "strong multicollinearity or other numerical problems.\n",
        "\"\"\""
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}