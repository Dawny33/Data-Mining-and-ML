{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load(test=False):\n",
    "    \n",
    "    if test:\n",
    "        X = pd.read_csv('test.csv')\n",
    "        X.drop(['Id'], axis=1, inplace=True)\n",
    "        y = None\n",
    "    else:\n",
    "        X = pd.read_csv('train.csv')\n",
    "        y = X[['Sales']].T.values[0]\n",
    "    \n",
    "    return X, y   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadStore():\n",
    "    return pd.read_csv('store.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_true-y_pred)/y_true) ** 2)\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "rmspe_scorer = make_scorer(rmspe, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmspe_xgb(y, predicted):\n",
    "    predicted = predicted.get_label()\n",
    "    return \"rmspe\", rmspe(y, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train,y = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test, _ = load(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store = loadStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = pd.merge(train, store, left_on='Store', right_on='Store', how='inner')\n",
    "test_df = pd.merge(test, store, left_on='Store', right_on='Store', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_df.csv').drop(['Unnamed: 0'], axis=1)\n",
    "test_df = pd.read_csv('test_df.csv').drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fill NaN with Open = 1, because sales in this days > 0\n",
    "test_df.Open.fillna(1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Getting some features from 'Date'\n",
    "train_df['Year'] = pd.to_datetime(train_df.Date).map(lambda x: x.year)\n",
    "train_df['DayOfYear'] = pd.to_datetime(train_df.Date).map(lambda x: x.dayofyear)\n",
    "train_df['Month'] = pd.to_datetime(train_df.Date).map(lambda x: x.month)\n",
    "\n",
    "test_df['Year'] = pd.to_datetime(test_df.Date).map(lambda x: x.year)\n",
    "test_df['DayOfYear'] = pd.to_datetime(test_df.Date).map(lambda x: x.dayofyear)\n",
    "test_df['Month'] = pd.to_datetime(test_df.Date).map(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Promo2 to 0 - if no Promo2, 1 - if in this day Promo2 is available\n",
    "train_df.Promo2SinceYear.fillna(2016, inplace=True)\n",
    "train_df.Promo2SinceWeek.fillna(1, inplace=True)\n",
    "train_df.PromoInterval.fillna(0, inplace=True)\n",
    "\n",
    "test_df.Promo2SinceYear.fillna(2016, inplace=True)\n",
    "test_df.Promo2SinceWeek.fillna(1, inplace=True)\n",
    "test_df.PromoInterval.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "dictionary1 = {0:0, 'Jan,Apr,Jul,Oct': 1, 'Feb,May,Aug,Nov': 2, 'Mar,Jun,Sept,Dec': 3}\n",
    "dictionary2 = {1:1, 4:1, 7:1, 10:1, 2:2, 5:2, 8:2, 11:2, 3:3, 6:3, 9:3, 12:3}\n",
    "\n",
    "train_df['PromoInterval'] = train_df['PromoInterval'].map(dictionary1)\n",
    "train_df['MonthInterval'] = train_df['Month'].map(dictionary2)\n",
    "\n",
    "test_df['PromoInterval'] = test_df['PromoInterval'].map(dictionary1)\n",
    "test_df['MonthInterval'] = test_df['Month'].map(dictionary2)\n",
    "\n",
    "\n",
    "\n",
    "train_df['Promo2'] = np.sign((train_df.Year - train_df.Promo2SinceYear) * 365 + \n",
    "                              (train_df.DayOfYear - train_df.Promo2SinceWeek * 7))\n",
    "\n",
    "test_df['Promo2'] = np.sign((test_df.Year - test_df.Promo2SinceYear) * 365 + \n",
    "                              (test_df.DayOfYear - test_df.Promo2SinceWeek * 7))\n",
    "\n",
    "def binarizePromo2(df):\n",
    "\n",
    "    promo2 = []\n",
    "    \n",
    "    for row in xrange(len(df)):\n",
    "\n",
    "        if df.Promo2[row] == 1 and df.PromoInterval[row] == df.MonthInterval[row]:\n",
    "            promo2.append(1)\n",
    "        else:\n",
    "            promo2.append(0)\n",
    "    \n",
    "    return promo2\n",
    "        \n",
    "train_df['Promo2'] = pd.DataFrame(binarizePromo2(train_df))\n",
    "test_df['Promo2'] = pd.DataFrame(binarizePromo2(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#CompetitionOpen in days\n",
    "train_df['CompetitionOpen'] = ((train_df.Year - train_df.CompetitionOpenSinceYear) * 365 + \n",
    "                                (train_df.DayOfYear - train_df.CompetitionOpenSinceMonth * 30))\n",
    "\n",
    "test_df['CompetitionOpen'] = ((test_df.Year - test_df.CompetitionOpenSinceYear) * 365 + \n",
    "                                (test_df.DayOfYear - test_df.CompetitionOpenSinceMonth * 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fill NaN with median\n",
    "med = train_df.CompetitionDistance.median()\n",
    "train_df['CompetitionDistance'] = train_df.CompetitionDistance.fillna(med)\n",
    "\n",
    "med = train_df.CompetitionOpen.median()\n",
    "train_df['CompetitionOpen'] = train_df.CompetitionOpen.fillna(med)\n",
    "\n",
    "\n",
    "med = test_df.CompetitionDistance.median()\n",
    "test_df['CompetitionDistance'] = test_df.CompetitionDistance.fillna(med)\n",
    "\n",
    "med = test_df.CompetitionOpen.median()\n",
    "test_df['CompetitionOpen'] = test_df.CompetitionOpen.fillna(med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.CompetitionDistance = train_df.CompetitionDistance.astype(int)\n",
    "train_df.CompetitionOpen = train_df.CompetitionOpen.astype(int)\n",
    "\n",
    "test_df.CompetitionDistance = test_df.CompetitionDistance.astype(int)\n",
    "test_df.CompetitionOpen = test_df.CompetitionOpen.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = train_df[train_df.Sales <> 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Category features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Category featores to digits\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_enc = LabelEncoder()\n",
    "\n",
    "enc_list = ['StoreType', 'Assortment', 'StateHoliday']\n",
    "\n",
    "for name in enc_list:\n",
    "    \n",
    "    train_df[name] = label_enc.fit_transform(train_df[name])\n",
    "    test_df[name] = label_enc.fit_transform(test_df[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.drop(['Promo2SinceYear', 'Promo2SinceWeek', 'CompetitionOpenSinceYear', \n",
    "'CompetitionOpenSinceMonth', 'PromoInterval', 'MonthInterval', 'Year'], axis=1, inplace=True)\n",
    "\n",
    "test_df.drop(['Promo2SinceYear', 'Promo2SinceWeek', 'CompetitionOpenSinceYear', \n",
    "'CompetitionOpenSinceMonth', 'PromoInterval', 'MonthInterval', 'Year'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metafeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Split dataset into the 2 parts 50/50\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "drop_cols = ['Open', 'Sales', 'Customers', 'Date']\n",
    "\n",
    "X = train_df.drop(drop_cols, axis=1).values\n",
    "y_c = train_df['Customers'].T.values\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y_c, test_size=0.50)\n",
    "\n",
    "test = test_df.drop(['Open', 'Date'], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train first half to predict 'Customers'\n",
    "#predict 'Customers' to the second half\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "clf = RandomForestRegressor(criterion='mse', n_jobs=-1, n_estimators=25, random_state=0)\n",
    "\n",
    "result_tr = [0, 0]\n",
    "result_te = [0, 0]\n",
    "\n",
    "clf.fit(X_tr, y_tr)\n",
    "result_tr[0] = clf.predict(X_te) \n",
    "result_te[0] = clf.predict(test) \n",
    "\n",
    "clf.fit(X_te, y_te)\n",
    "result_tr[1] = clf.predict(X_tr) \n",
    "result_te[1] = clf.predict(test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for test avarage of 2 predictions\n",
    "train_df['Meta'] = np.concatenate((result_tr[0], result_tr[1]), axis=0).astype(int)\n",
    "test_df['Meta'] = ((result_te[0] + result_te[1]) / 2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.to_csv('train_df.csv')\n",
    "test_df.to_csv('test_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xgboost\n",
    "\n",
    "def fit_xgb(X_tr, X_te, y_tr, y_te):\n",
    "    xgb_tr, xgb_te, yxgb_tr, yxgb_te = train_test_split(X_tr, y_tr, test_size=0.2, random_state=10)\n",
    "\n",
    "    dtrain = xgboost.DMatrix(xgb_tr, label = yxgb_tr)\n",
    "    dval = xgboost.DMatrix(xgb_te, label = yxgb_te)\n",
    "\n",
    "\n",
    "    params = {'objective': 'reg:linear',\n",
    "              'booster': 'gbtree',\n",
    "              'eta': 0.3,\n",
    "              'max_depth': 13,\n",
    "              'subsample': 0.9,\n",
    "              'colsample_bytree': 0.7,\n",
    "              'silent': 1,\n",
    "              'seed': 1001,\n",
    "              'nthread': 4\n",
    "              }\n",
    "    num_round = 300\n",
    "\n",
    "    plst = list(params.items())\n",
    "\n",
    "    evallist  = [(dval,'eval'), (dtrain,'train')]\n",
    "\n",
    "    bst = xgboost.train( plst, dtrain, num_round, evallist, early_stopping_rounds=150, feval=rmspe_xgb, verbose_eval=True)\n",
    "\n",
    "    y_val = bst.predict(xgboost.DMatrix(X_te))\n",
    "\n",
    "    print 'Error', np.fabs(rmspe(y_te, y_val))\n",
    "    \n",
    "    return bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split on time\n",
    "drop_cols = ['Open', 'Sales', 'Customers', 'Date']\n",
    "\n",
    "mask = [(pd.to_datetime(train_df.Date) < np.datetime64('2015-06-01T00:00:00.000000000+0000'),\n",
    "        pd.to_datetime(train_df.Date) >= np.datetime64('2015-06-01T00:00:00.000000000+0000'))]\n",
    "\n",
    "y_tr = train_df.loc[mask[0][0]].Sales.T.values\n",
    "y_te = train_df.loc[mask[0][1]].Sales.T.values\n",
    "\n",
    "X_tr = train_df.loc[mask[0][0], :].drop(drop_cols, axis=1).values\n",
    "X_te = train_df.loc[mask[0][1], :].drop(drop_cols, axis=1).values\n",
    "\n",
    "test = test_df.drop(['Open', 'Date'], axis=1).values\n",
    "\n",
    "cols = train_df.drop(drop_cols, axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until train error hasn't decreased in 150 rounds.\n",
      "[0]\teval-rmspe:2.347864\ttrain-rmspe:2.341150\n",
      "[1]\teval-rmspe:0.939040\ttrain-rmspe:0.936635\n",
      "[2]\teval-rmspe:0.498209\ttrain-rmspe:0.496364\n",
      "[3]\teval-rmspe:0.291911\ttrain-rmspe:0.290270\n",
      "[4]\teval-rmspe:0.178625\ttrain-rmspe:0.177037\n",
      "[5]\teval-rmspe:0.109437\ttrain-rmspe:0.107920\n",
      "[6]\teval-rmspe:0.065287\ttrain-rmspe:0.063789\n",
      "[7]\teval-rmspe:0.037720\ttrain-rmspe:0.036255\n",
      "[8]\teval-rmspe:0.019719\ttrain-rmspe:0.018366\n",
      "[9]\teval-rmspe:0.007956\ttrain-rmspe:0.006562\n",
      "[10]\teval-rmspe:0.000528\ttrain-rmspe:0.001907\n",
      "[11]\teval-rmspe:0.006076\ttrain-rmspe:0.007427\n",
      "[12]\teval-rmspe:0.009890\ttrain-rmspe:0.011057\n",
      "[13]\teval-rmspe:0.012503\ttrain-rmspe:0.013550\n",
      "[14]\teval-rmspe:0.013777\ttrain-rmspe:0.014878\n",
      "[15]\teval-rmspe:0.014240\ttrain-rmspe:0.015262\n",
      "[16]\teval-rmspe:0.014542\ttrain-rmspe:0.015387\n",
      "[17]\teval-rmspe:0.014596\ttrain-rmspe:0.015508\n",
      "[18]\teval-rmspe:0.014500\ttrain-rmspe:0.015328\n",
      "[19]\teval-rmspe:0.014460\ttrain-rmspe:0.015340\n",
      "[20]\teval-rmspe:0.014362\ttrain-rmspe:0.015203\n",
      "[21]\teval-rmspe:0.014341\ttrain-rmspe:0.015149\n",
      "[22]\teval-rmspe:0.013826\ttrain-rmspe:0.014456\n",
      "[23]\teval-rmspe:0.013600\ttrain-rmspe:0.014210\n",
      "[24]\teval-rmspe:0.012660\ttrain-rmspe:0.013214\n",
      "[25]\teval-rmspe:0.012404\ttrain-rmspe:0.012924\n",
      "[26]\teval-rmspe:0.011621\ttrain-rmspe:0.012056\n",
      "[27]\teval-rmspe:0.010932\ttrain-rmspe:0.011303\n",
      "[28]\teval-rmspe:0.010657\ttrain-rmspe:0.011011\n",
      "[29]\teval-rmspe:0.010398\ttrain-rmspe:0.010789\n",
      "[30]\teval-rmspe:0.010231\ttrain-rmspe:0.010602\n",
      "[31]\teval-rmspe:0.010025\ttrain-rmspe:0.010394\n",
      "[32]\teval-rmspe:0.009733\ttrain-rmspe:0.010109\n",
      "[33]\teval-rmspe:0.009293\ttrain-rmspe:0.009662\n",
      "[34]\teval-rmspe:0.009111\ttrain-rmspe:0.009421\n",
      "[35]\teval-rmspe:0.008825\ttrain-rmspe:0.009105\n",
      "[36]\teval-rmspe:0.008308\ttrain-rmspe:0.008621\n",
      "[37]\teval-rmspe:0.008116\ttrain-rmspe:0.008438\n",
      "[38]\teval-rmspe:0.007941\ttrain-rmspe:0.008259\n",
      "[39]\teval-rmspe:0.007745\ttrain-rmspe:0.008074\n",
      "[40]\teval-rmspe:0.007593\ttrain-rmspe:0.007879\n",
      "[41]\teval-rmspe:0.007212\ttrain-rmspe:0.007491\n",
      "[42]\teval-rmspe:0.006979\ttrain-rmspe:0.007249\n",
      "[43]\teval-rmspe:0.005986\ttrain-rmspe:0.006296\n",
      "[44]\teval-rmspe:0.005385\ttrain-rmspe:0.005707\n",
      "[45]\teval-rmspe:0.005195\ttrain-rmspe:0.005526\n",
      "[46]\teval-rmspe:0.004726\ttrain-rmspe:0.004930\n",
      "[47]\teval-rmspe:0.004649\ttrain-rmspe:0.004868\n",
      "[48]\teval-rmspe:0.004334\ttrain-rmspe:0.003853\n",
      "[49]\teval-rmspe:0.004100\ttrain-rmspe:0.004490\n",
      "[50]\teval-rmspe:0.004020\ttrain-rmspe:0.004406\n",
      "[51]\teval-rmspe:0.003929\ttrain-rmspe:0.004330\n",
      "[52]\teval-rmspe:0.003694\ttrain-rmspe:0.004056\n",
      "[53]\teval-rmspe:0.003439\ttrain-rmspe:0.003762\n",
      "[54]\teval-rmspe:0.003368\ttrain-rmspe:0.003712\n",
      "[55]\teval-rmspe:0.003179\ttrain-rmspe:0.003504\n",
      "[56]\teval-rmspe:0.003073\ttrain-rmspe:0.003376\n",
      "[57]\teval-rmspe:0.002903\ttrain-rmspe:0.003230\n",
      "[58]\teval-rmspe:0.002727\ttrain-rmspe:0.003047\n",
      "[59]\teval-rmspe:0.002685\ttrain-rmspe:0.002952\n",
      "[60]\teval-rmspe:0.002607\ttrain-rmspe:0.002885\n",
      "[61]\teval-rmspe:0.002535\ttrain-rmspe:0.002866\n",
      "[62]\teval-rmspe:0.002415\ttrain-rmspe:0.002785\n",
      "[63]\teval-rmspe:0.002365\ttrain-rmspe:0.002760\n",
      "[64]\teval-rmspe:0.002254\ttrain-rmspe:0.002660\n",
      "[65]\teval-rmspe:0.002203\ttrain-rmspe:0.002621\n",
      "[66]\teval-rmspe:0.002116\ttrain-rmspe:0.002511\n",
      "[67]\teval-rmspe:0.002078\ttrain-rmspe:0.002507\n",
      "[68]\teval-rmspe:0.001933\ttrain-rmspe:0.002404\n",
      "[69]\teval-rmspe:0.001875\ttrain-rmspe:0.002362\n",
      "[70]\teval-rmspe:0.001855\ttrain-rmspe:0.002340\n",
      "[71]\teval-rmspe:0.001837\ttrain-rmspe:0.002340\n",
      "[72]\teval-rmspe:0.001830\ttrain-rmspe:0.002336\n",
      "[73]\teval-rmspe:0.001772\ttrain-rmspe:0.002285\n",
      "[74]\teval-rmspe:0.001743\ttrain-rmspe:0.002252\n",
      "[75]\teval-rmspe:0.001707\ttrain-rmspe:0.002232\n",
      "[76]\teval-rmspe:0.001606\ttrain-rmspe:0.002139\n",
      "[77]\teval-rmspe:0.001451\ttrain-rmspe:0.001996\n",
      "[78]\teval-rmspe:0.001430\ttrain-rmspe:0.001986\n",
      "[79]\teval-rmspe:0.001409\ttrain-rmspe:0.001976\n",
      "[80]\teval-rmspe:0.001370\ttrain-rmspe:0.001958\n",
      "[81]\teval-rmspe:0.001330\ttrain-rmspe:0.001941\n",
      "[82]\teval-rmspe:0.001180\ttrain-rmspe:0.001814\n",
      "[83]\teval-rmspe:0.001220\ttrain-rmspe:0.001851\n",
      "[84]\teval-rmspe:0.001167\ttrain-rmspe:0.001816\n",
      "[85]\teval-rmspe:0.001111\ttrain-rmspe:0.001755\n",
      "[86]\teval-rmspe:0.001109\ttrain-rmspe:0.001760\n",
      "[87]\teval-rmspe:0.001098\ttrain-rmspe:0.001762\n",
      "[88]\teval-rmspe:0.001062\ttrain-rmspe:0.001743\n",
      "[89]\teval-rmspe:0.001021\ttrain-rmspe:0.001739\n",
      "[90]\teval-rmspe:0.000968\ttrain-rmspe:0.001672\n",
      "[91]\teval-rmspe:0.000943\ttrain-rmspe:0.001658\n",
      "[92]\teval-rmspe:0.000932\ttrain-rmspe:0.001666\n",
      "[93]\teval-rmspe:0.000910\ttrain-rmspe:0.001667\n",
      "[94]\teval-rmspe:0.000865\ttrain-rmspe:0.001629\n",
      "[95]\teval-rmspe:0.000831\ttrain-rmspe:0.001600\n",
      "[96]\teval-rmspe:0.000786\ttrain-rmspe:0.001604\n",
      "[97]\teval-rmspe:0.000755\ttrain-rmspe:0.001581\n",
      "[98]\teval-rmspe:0.000705\ttrain-rmspe:0.001527\n",
      "[99]\teval-rmspe:0.000650\ttrain-rmspe:0.001469\n",
      "[100]\teval-rmspe:0.000599\ttrain-rmspe:0.001423\n",
      "[101]\teval-rmspe:0.000567\ttrain-rmspe:0.001431\n",
      "[102]\teval-rmspe:0.000525\ttrain-rmspe:0.001384\n",
      "[103]\teval-rmspe:0.000515\ttrain-rmspe:0.001387\n",
      "[104]\teval-rmspe:0.000480\ttrain-rmspe:0.001358\n",
      "[105]\teval-rmspe:0.000408\ttrain-rmspe:0.001280\n",
      "[106]\teval-rmspe:0.000374\ttrain-rmspe:0.001261\n",
      "[107]\teval-rmspe:0.000370\ttrain-rmspe:0.001281\n",
      "[108]\teval-rmspe:0.000315\ttrain-rmspe:0.001238\n",
      "[109]\teval-rmspe:0.000309\ttrain-rmspe:0.001253\n",
      "[110]\teval-rmspe:0.000276\ttrain-rmspe:0.001230\n",
      "[111]\teval-rmspe:0.000258\ttrain-rmspe:0.001216\n",
      "[112]\teval-rmspe:0.000257\ttrain-rmspe:0.001212\n",
      "[113]\teval-rmspe:0.000236\ttrain-rmspe:0.001203\n",
      "[114]\teval-rmspe:0.000182\ttrain-rmspe:0.001137\n",
      "[115]\teval-rmspe:0.000161\ttrain-rmspe:0.001139\n",
      "[116]\teval-rmspe:0.000136\ttrain-rmspe:0.001130\n",
      "[117]\teval-rmspe:0.000113\ttrain-rmspe:0.001137\n",
      "[118]\teval-rmspe:0.000104\ttrain-rmspe:0.001139\n",
      "[119]\teval-rmspe:0.000098\ttrain-rmspe:0.001140\n",
      "[120]\teval-rmspe:0.000095\ttrain-rmspe:0.001133\n",
      "[121]\teval-rmspe:0.000105\ttrain-rmspe:0.001122\n",
      "[122]\teval-rmspe:0.000099\ttrain-rmspe:0.001118\n",
      "[123]\teval-rmspe:0.000094\ttrain-rmspe:0.001114\n",
      "[124]\teval-rmspe:0.000034\ttrain-rmspe:0.001051\n",
      "[125]\teval-rmspe:0.000043\ttrain-rmspe:0.001060\n",
      "[126]\teval-rmspe:0.000038\ttrain-rmspe:0.001087\n",
      "[127]\teval-rmspe:0.000011\ttrain-rmspe:0.001059\n",
      "[128]\teval-rmspe:0.000039\ttrain-rmspe:0.001042\n",
      "[129]\teval-rmspe:0.000050\ttrain-rmspe:0.001042\n",
      "[130]\teval-rmspe:0.000057\ttrain-rmspe:0.001045\n",
      "[131]\teval-rmspe:0.000064\ttrain-rmspe:0.001036\n",
      "[132]\teval-rmspe:0.000099\ttrain-rmspe:0.001034\n",
      "[133]\teval-rmspe:0.000106\ttrain-rmspe:0.001028\n",
      "[134]\teval-rmspe:0.000141\ttrain-rmspe:0.001005\n",
      "[135]\teval-rmspe:0.000133\ttrain-rmspe:0.001014\n",
      "[136]\teval-rmspe:0.000107\ttrain-rmspe:0.001048\n",
      "[137]\teval-rmspe:0.000129\ttrain-rmspe:0.001050\n",
      "[138]\teval-rmspe:0.000134\ttrain-rmspe:0.001046\n",
      "[139]\teval-rmspe:0.000164\ttrain-rmspe:0.001036\n",
      "[140]\teval-rmspe:0.000179\ttrain-rmspe:0.001033\n",
      "[141]\teval-rmspe:0.000191\ttrain-rmspe:0.001038\n",
      "[142]\teval-rmspe:0.000222\ttrain-rmspe:0.001025\n",
      "[143]\teval-rmspe:0.000223\ttrain-rmspe:0.001027\n",
      "[144]\teval-rmspe:0.000250\ttrain-rmspe:0.001013\n",
      "[145]\teval-rmspe:0.000289\ttrain-rmspe:0.000999\n",
      "[146]\teval-rmspe:0.000311\ttrain-rmspe:0.000995\n",
      "[147]\teval-rmspe:0.000335\ttrain-rmspe:0.000991\n",
      "[148]\teval-rmspe:0.000326\ttrain-rmspe:0.000995\n",
      "[149]\teval-rmspe:0.000345\ttrain-rmspe:0.000990\n",
      "[150]\teval-rmspe:0.000365\ttrain-rmspe:0.000963\n",
      "[151]\teval-rmspe:0.000368\ttrain-rmspe:0.000969\n",
      "[152]\teval-rmspe:0.000401\ttrain-rmspe:0.000960\n",
      "[153]\teval-rmspe:0.000396\ttrain-rmspe:0.000971\n",
      "[154]\teval-rmspe:0.000404\ttrain-rmspe:0.000964\n",
      "[155]\teval-rmspe:0.000470\ttrain-rmspe:0.000910\n",
      "[156]\teval-rmspe:0.000463\ttrain-rmspe:0.000928\n",
      "[157]\teval-rmspe:0.000465\ttrain-rmspe:0.000929\n",
      "[158]\teval-rmspe:0.000461\ttrain-rmspe:0.000937\n",
      "[159]\teval-rmspe:0.000490\ttrain-rmspe:0.000918\n",
      "[160]\teval-rmspe:0.000510\ttrain-rmspe:0.000895\n",
      "[161]\teval-rmspe:0.000502\ttrain-rmspe:0.000900\n",
      "[162]\teval-rmspe:0.000516\ttrain-rmspe:0.000907\n",
      "[163]\teval-rmspe:0.000528\ttrain-rmspe:0.000902\n",
      "[164]\teval-rmspe:0.000534\ttrain-rmspe:0.000912\n",
      "[165]\teval-rmspe:0.000595\ttrain-rmspe:0.000853\n",
      "[166]\teval-rmspe:0.000600\ttrain-rmspe:0.000853\n",
      "[167]\teval-rmspe:0.000593\ttrain-rmspe:0.000861\n",
      "[168]\teval-rmspe:0.000627\ttrain-rmspe:0.000870\n",
      "[169]\teval-rmspe:0.000640\ttrain-rmspe:0.000882\n",
      "[170]\teval-rmspe:0.000679\ttrain-rmspe:0.000859\n",
      "[171]\teval-rmspe:0.000690\ttrain-rmspe:0.000852\n",
      "[172]\teval-rmspe:0.000689\ttrain-rmspe:0.000852\n",
      "[173]\teval-rmspe:0.000691\ttrain-rmspe:0.000866\n",
      "[174]\teval-rmspe:0.000698\ttrain-rmspe:0.000859\n",
      "[175]\teval-rmspe:0.000704\ttrain-rmspe:0.000868\n",
      "[176]\teval-rmspe:0.000696\ttrain-rmspe:0.000878\n",
      "[177]\teval-rmspe:0.000724\ttrain-rmspe:0.000874\n",
      "[178]\teval-rmspe:0.000742\ttrain-rmspe:0.000866\n",
      "[179]\teval-rmspe:0.000735\ttrain-rmspe:0.000869\n",
      "[180]\teval-rmspe:0.000742\ttrain-rmspe:0.000860\n",
      "[181]\teval-rmspe:0.000765\ttrain-rmspe:0.000849\n",
      "[182]\teval-rmspe:0.000786\ttrain-rmspe:0.000837\n",
      "[183]\teval-rmspe:0.000787\ttrain-rmspe:0.000846\n",
      "[184]\teval-rmspe:0.000792\ttrain-rmspe:0.000853\n",
      "[185]\teval-rmspe:0.000799\ttrain-rmspe:0.000852\n",
      "[186]\teval-rmspe:0.000793\ttrain-rmspe:0.000859\n",
      "[187]\teval-rmspe:0.000793\ttrain-rmspe:0.000860\n",
      "[188]\teval-rmspe:0.000765\ttrain-rmspe:0.000882\n",
      "[189]\teval-rmspe:0.000762\ttrain-rmspe:0.000890\n",
      "[190]\teval-rmspe:0.000789\ttrain-rmspe:0.000866\n",
      "[191]\teval-rmspe:0.000772\ttrain-rmspe:0.000874\n",
      "[192]\teval-rmspe:0.000801\ttrain-rmspe:0.000854\n",
      "[193]\teval-rmspe:0.000832\ttrain-rmspe:0.000833\n",
      "[194]\teval-rmspe:0.000835\ttrain-rmspe:0.000833\n",
      "[195]\teval-rmspe:0.000840\ttrain-rmspe:0.000831\n",
      "[196]\teval-rmspe:0.000838\ttrain-rmspe:0.000833\n",
      "[197]\teval-rmspe:0.000833\ttrain-rmspe:0.000839\n",
      "[198]\teval-rmspe:0.000847\ttrain-rmspe:0.000836\n",
      "[199]\teval-rmspe:0.000875\ttrain-rmspe:0.000805\n",
      "[200]\teval-rmspe:0.000870\ttrain-rmspe:0.000818\n",
      "[201]\teval-rmspe:0.000864\ttrain-rmspe:0.000825\n",
      "[202]\teval-rmspe:0.000861\ttrain-rmspe:0.000831\n",
      "[203]\teval-rmspe:0.000881\ttrain-rmspe:0.000831\n",
      "[204]\teval-rmspe:0.000888\ttrain-rmspe:0.000835\n",
      "[205]\teval-rmspe:0.000896\ttrain-rmspe:0.000825\n",
      "[206]\teval-rmspe:0.000891\ttrain-rmspe:0.000834\n",
      "[207]\teval-rmspe:0.000897\ttrain-rmspe:0.000839\n",
      "[208]\teval-rmspe:0.000890\ttrain-rmspe:0.000839\n",
      "[209]\teval-rmspe:0.000882\ttrain-rmspe:0.000856\n",
      "[210]\teval-rmspe:0.000887\ttrain-rmspe:0.000860\n",
      "[211]\teval-rmspe:0.000879\ttrain-rmspe:0.000864\n",
      "[212]\teval-rmspe:0.000868\ttrain-rmspe:0.000879\n",
      "[213]\teval-rmspe:0.000907\ttrain-rmspe:0.000860\n",
      "[214]\teval-rmspe:0.000941\ttrain-rmspe:0.000855\n",
      "[215]\teval-rmspe:0.000957\ttrain-rmspe:0.000849\n",
      "[216]\teval-rmspe:0.000960\ttrain-rmspe:0.000848\n",
      "[217]\teval-rmspe:0.000973\ttrain-rmspe:0.000840\n",
      "[218]\teval-rmspe:0.000975\ttrain-rmspe:0.000848\n",
      "[219]\teval-rmspe:0.000971\ttrain-rmspe:0.000847\n",
      "[220]\teval-rmspe:0.000964\ttrain-rmspe:0.000854\n",
      "[221]\teval-rmspe:0.000986\ttrain-rmspe:0.000845\n",
      "[222]\teval-rmspe:0.001004\ttrain-rmspe:0.000841\n",
      "[223]\teval-rmspe:0.001014\ttrain-rmspe:0.000838\n",
      "[224]\teval-rmspe:0.001015\ttrain-rmspe:0.000858\n",
      "[225]\teval-rmspe:0.001030\ttrain-rmspe:0.000865\n",
      "[226]\teval-rmspe:0.001032\ttrain-rmspe:0.000872\n",
      "[227]\teval-rmspe:0.001032\ttrain-rmspe:0.000873\n",
      "[228]\teval-rmspe:0.001036\ttrain-rmspe:0.000874\n",
      "[229]\teval-rmspe:0.001043\ttrain-rmspe:0.000878\n",
      "[230]\teval-rmspe:0.001051\ttrain-rmspe:0.000873\n",
      "[231]\teval-rmspe:0.001083\ttrain-rmspe:0.000864\n",
      "[232]\teval-rmspe:0.001082\ttrain-rmspe:0.000867\n",
      "[233]\teval-rmspe:0.001101\ttrain-rmspe:0.000845\n",
      "[234]\teval-rmspe:0.001111\ttrain-rmspe:0.000844\n",
      "[235]\teval-rmspe:0.001107\ttrain-rmspe:0.000848\n",
      "[236]\teval-rmspe:0.001106\ttrain-rmspe:0.000842\n",
      "[237]\teval-rmspe:0.001091\ttrain-rmspe:0.000855\n",
      "[238]\teval-rmspe:0.001092\ttrain-rmspe:0.000864\n",
      "[239]\teval-rmspe:0.001082\ttrain-rmspe:0.000873\n",
      "[240]\teval-rmspe:0.001070\ttrain-rmspe:0.000868\n",
      "[241]\teval-rmspe:0.001096\ttrain-rmspe:0.000859\n",
      "[242]\teval-rmspe:0.001097\ttrain-rmspe:0.000862\n",
      "[243]\teval-rmspe:0.001084\ttrain-rmspe:0.000875\n",
      "[244]\teval-rmspe:0.001083\ttrain-rmspe:0.000877\n",
      "[245]\teval-rmspe:0.001100\ttrain-rmspe:0.000872\n",
      "[246]\teval-rmspe:0.001135\ttrain-rmspe:0.000867\n",
      "[247]\teval-rmspe:0.001134\ttrain-rmspe:0.000871\n",
      "[248]\teval-rmspe:0.001138\ttrain-rmspe:0.000873\n",
      "[249]\teval-rmspe:0.001137\ttrain-rmspe:0.000870\n",
      "[250]\teval-rmspe:0.001139\ttrain-rmspe:0.000869\n",
      "[251]\teval-rmspe:0.001140\ttrain-rmspe:0.000874\n",
      "[252]\teval-rmspe:0.001126\ttrain-rmspe:0.000882\n",
      "[253]\teval-rmspe:0.001144\ttrain-rmspe:0.000864\n",
      "[254]\teval-rmspe:0.001156\ttrain-rmspe:0.000872\n",
      "[255]\teval-rmspe:0.001170\ttrain-rmspe:0.000870\n",
      "[256]\teval-rmspe:0.001148\ttrain-rmspe:0.000868\n",
      "[257]\teval-rmspe:0.001148\ttrain-rmspe:0.000866\n",
      "[258]\teval-rmspe:0.001157\ttrain-rmspe:0.000866\n",
      "[259]\teval-rmspe:0.001148\ttrain-rmspe:0.000871\n",
      "[260]\teval-rmspe:0.001159\ttrain-rmspe:0.000872\n",
      "[261]\teval-rmspe:0.001170\ttrain-rmspe:0.000887\n",
      "[262]\teval-rmspe:0.001166\ttrain-rmspe:0.000887\n",
      "[263]\teval-rmspe:0.001174\ttrain-rmspe:0.000894\n",
      "[264]\teval-rmspe:0.001183\ttrain-rmspe:0.000888\n",
      "[265]\teval-rmspe:0.001204\ttrain-rmspe:0.000875\n",
      "[266]\teval-rmspe:0.001214\ttrain-rmspe:0.000870\n",
      "[267]\teval-rmspe:0.001239\ttrain-rmspe:0.000875\n",
      "[268]\teval-rmspe:0.001239\ttrain-rmspe:0.000885\n",
      "[269]\teval-rmspe:0.001227\ttrain-rmspe:0.000891\n",
      "[270]\teval-rmspe:0.001245\ttrain-rmspe:0.000899\n",
      "[271]\teval-rmspe:0.001248\ttrain-rmspe:0.000893\n",
      "[272]\teval-rmspe:0.001246\ttrain-rmspe:0.000901\n",
      "[273]\teval-rmspe:0.001234\ttrain-rmspe:0.000922\n",
      "[274]\teval-rmspe:0.001239\ttrain-rmspe:0.000914\n",
      "[275]\teval-rmspe:0.001245\ttrain-rmspe:0.000910\n",
      "[276]\teval-rmspe:0.001245\ttrain-rmspe:0.000911\n",
      "[277]\teval-rmspe:0.001252\ttrain-rmspe:0.000912\n",
      "[278]\teval-rmspe:0.001265\ttrain-rmspe:0.000903\n",
      "[279]\teval-rmspe:0.001259\ttrain-rmspe:0.000913\n",
      "[280]\teval-rmspe:0.001277\ttrain-rmspe:0.000904\n",
      "[281]\teval-rmspe:0.001278\ttrain-rmspe:0.000906\n",
      "[282]\teval-rmspe:0.001271\ttrain-rmspe:0.000913\n",
      "[283]\teval-rmspe:0.001280\ttrain-rmspe:0.000901\n",
      "[284]\teval-rmspe:0.001276\ttrain-rmspe:0.000913\n",
      "[285]\teval-rmspe:0.001265\ttrain-rmspe:0.000928\n",
      "[286]\teval-rmspe:0.001286\ttrain-rmspe:0.000926\n",
      "[287]\teval-rmspe:0.001279\ttrain-rmspe:0.000938\n",
      "[288]\teval-rmspe:0.001283\ttrain-rmspe:0.000936\n",
      "[289]\teval-rmspe:0.001293\ttrain-rmspe:0.000932\n",
      "[290]\teval-rmspe:0.001301\ttrain-rmspe:0.000935\n",
      "[291]\teval-rmspe:0.001314\ttrain-rmspe:0.000929\n",
      "[292]\teval-rmspe:0.001264\ttrain-rmspe:0.000915\n",
      "[293]\teval-rmspe:0.001256\ttrain-rmspe:0.000922\n",
      "[294]\teval-rmspe:0.001268\ttrain-rmspe:0.000923\n",
      "[295]\teval-rmspe:0.001282\ttrain-rmspe:0.000916\n",
      "[296]\teval-rmspe:0.001280\ttrain-rmspe:0.000921\n",
      "[297]\teval-rmspe:0.001277\ttrain-rmspe:0.000926\n",
      "[298]\teval-rmspe:0.001284\ttrain-rmspe:0.000925\n",
      "[299]\teval-rmspe:0.001265\ttrain-rmspe:0.000932\n",
      "[300]\teval-rmspe:0.001272\ttrain-rmspe:0.000920\n",
      "[301]\teval-rmspe:0.001265\ttrain-rmspe:0.000928\n",
      "[302]\teval-rmspe:0.001251\ttrain-rmspe:0.000945\n",
      "[303]\teval-rmspe:0.001262\ttrain-rmspe:0.000937\n",
      "[304]\teval-rmspe:0.001269\ttrain-rmspe:0.000930\n",
      "[305]\teval-rmspe:0.001267\ttrain-rmspe:0.000932\n",
      "[306]\teval-rmspe:0.001276\ttrain-rmspe:0.000925\n",
      "[307]\teval-rmspe:0.001278\ttrain-rmspe:0.000926\n",
      "[308]\teval-rmspe:0.001277\ttrain-rmspe:0.000929\n",
      "[309]\teval-rmspe:0.001280\ttrain-rmspe:0.000940\n",
      "[310]\teval-rmspe:0.001281\ttrain-rmspe:0.000941\n",
      "[311]\teval-rmspe:0.001293\ttrain-rmspe:0.000926\n",
      "[312]\teval-rmspe:0.001300\ttrain-rmspe:0.000926\n",
      "[313]\teval-rmspe:0.001266\ttrain-rmspe:0.000936\n",
      "[314]\teval-rmspe:0.001270\ttrain-rmspe:0.000924\n",
      "[315]\teval-rmspe:0.001284\ttrain-rmspe:0.000924\n",
      "[316]\teval-rmspe:0.001275\ttrain-rmspe:0.000932\n",
      "[317]\teval-rmspe:0.001277\ttrain-rmspe:0.000927\n",
      "[318]\teval-rmspe:0.001281\ttrain-rmspe:0.000925\n",
      "[319]\teval-rmspe:0.001278\ttrain-rmspe:0.000935\n",
      "[320]\teval-rmspe:0.001294\ttrain-rmspe:0.000917\n",
      "[321]\teval-rmspe:0.001310\ttrain-rmspe:0.000913\n",
      "[322]\teval-rmspe:0.001308\ttrain-rmspe:0.000914\n",
      "[323]\teval-rmspe:0.001298\ttrain-rmspe:0.000928\n",
      "[324]\teval-rmspe:0.001309\ttrain-rmspe:0.000918\n",
      "[325]\teval-rmspe:0.001327\ttrain-rmspe:0.000905\n",
      "[326]\teval-rmspe:0.001329\ttrain-rmspe:0.000907\n",
      "[327]\teval-rmspe:0.001332\ttrain-rmspe:0.000906\n",
      "[328]\teval-rmspe:0.001326\ttrain-rmspe:0.000916\n",
      "[329]\teval-rmspe:0.001332\ttrain-rmspe:0.000912\n",
      "[330]\teval-rmspe:0.001340\ttrain-rmspe:0.000911\n",
      "[331]\teval-rmspe:0.001351\ttrain-rmspe:0.000906\n",
      "[332]\teval-rmspe:0.001342\ttrain-rmspe:0.000917\n",
      "[333]\teval-rmspe:0.001342\ttrain-rmspe:0.000917\n",
      "[334]\teval-rmspe:0.001345\ttrain-rmspe:0.000916\n",
      "[335]\teval-rmspe:0.001326\ttrain-rmspe:0.000926\n",
      "[336]\teval-rmspe:0.001323\ttrain-rmspe:0.000931\n",
      "[337]\teval-rmspe:0.001348\ttrain-rmspe:0.000916\n",
      "[338]\teval-rmspe:0.001355\ttrain-rmspe:0.000918\n",
      "[339]\teval-rmspe:0.001366\ttrain-rmspe:0.000911\n",
      "[340]\teval-rmspe:0.001376\ttrain-rmspe:0.000903\n",
      "[341]\teval-rmspe:0.001380\ttrain-rmspe:0.000910\n",
      "[342]\teval-rmspe:0.001385\ttrain-rmspe:0.000912\n",
      "[343]\teval-rmspe:0.001387\ttrain-rmspe:0.000915\n",
      "[344]\teval-rmspe:0.001390\ttrain-rmspe:0.000915\n",
      "[345]\teval-rmspe:0.001387\ttrain-rmspe:0.000917\n",
      "[346]\teval-rmspe:0.001384\ttrain-rmspe:0.000920\n",
      "[347]\teval-rmspe:0.001390\ttrain-rmspe:0.000925\n",
      "[348]\teval-rmspe:0.001380\ttrain-rmspe:0.000928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 0.00376351296038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[349]\teval-rmspe:0.001374\ttrain-rmspe:0.000934\n",
      "Stopping. Best iteration:\n",
      "[199]\teval-rmspe:0.000875\ttrain-rmspe:0.000805\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bst = fit_xgb(X_tr, X_te, y_tr, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#split on random\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "drop_cols = ['Open', 'Sales', 'Customers', 'Date']\n",
    "\n",
    "y = train_df['Sales'].T.values\n",
    "X = train_df.drop(drop_cols, axis=1).values\n",
    "\n",
    "test = test_df.drop(['Open', 'Date'], axis=1).values\n",
    "\n",
    "cols = train_df.drop(drop_cols, axis=1).columns\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.25, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until train error hasn't decreased in 150 rounds.\n",
      "[0]\teval-rmspe:2.341537\ttrain-rmspe:2.339708\n",
      "[1]\teval-rmspe:0.948128\ttrain-rmspe:0.946370\n",
      "[2]\teval-rmspe:0.505538\ttrain-rmspe:0.503917\n",
      "[3]\teval-rmspe:0.293963\ttrain-rmspe:0.292700\n",
      "[4]\teval-rmspe:0.181760\ttrain-rmspe:0.180721\n",
      "[5]\teval-rmspe:0.111527\ttrain-rmspe:0.110680\n",
      "[6]\teval-rmspe:0.068449\ttrain-rmspe:0.067730\n",
      "[7]\teval-rmspe:0.040364\ttrain-rmspe:0.039611\n",
      "[8]\teval-rmspe:0.021799\ttrain-rmspe:0.021068\n",
      "[9]\teval-rmspe:0.008961\ttrain-rmspe:0.008155\n",
      "[10]\teval-rmspe:0.000558\ttrain-rmspe:0.000249\n",
      "[11]\teval-rmspe:0.005416\ttrain-rmspe:0.006163\n",
      "[12]\teval-rmspe:0.009425\ttrain-rmspe:0.010235\n",
      "[13]\teval-rmspe:0.012019\ttrain-rmspe:0.012943\n",
      "[14]\teval-rmspe:0.013823\ttrain-rmspe:0.014600\n",
      "[15]\teval-rmspe:0.014998\ttrain-rmspe:0.015809\n",
      "[16]\teval-rmspe:0.015451\ttrain-rmspe:0.016338\n",
      "[17]\teval-rmspe:0.015637\ttrain-rmspe:0.016521\n",
      "[18]\teval-rmspe:0.015415\ttrain-rmspe:0.016109\n",
      "[19]\teval-rmspe:0.015573\ttrain-rmspe:0.016288\n",
      "[20]\teval-rmspe:0.015259\ttrain-rmspe:0.015932\n",
      "[21]\teval-rmspe:0.014847\ttrain-rmspe:0.015386\n",
      "[22]\teval-rmspe:0.014753\ttrain-rmspe:0.015340\n",
      "[23]\teval-rmspe:0.014233\ttrain-rmspe:0.014794\n",
      "[24]\teval-rmspe:0.013802\ttrain-rmspe:0.014269\n",
      "[25]\teval-rmspe:0.012879\ttrain-rmspe:0.013320\n",
      "[26]\teval-rmspe:0.012589\ttrain-rmspe:0.012986\n",
      "[27]\teval-rmspe:0.011595\ttrain-rmspe:0.011925\n",
      "[28]\teval-rmspe:0.011220\ttrain-rmspe:0.011522\n",
      "[29]\teval-rmspe:0.010506\ttrain-rmspe:0.010857\n",
      "[30]\teval-rmspe:0.010167\ttrain-rmspe:0.010525\n",
      "[31]\teval-rmspe:0.009797\ttrain-rmspe:0.010162\n",
      "[32]\teval-rmspe:0.009246\ttrain-rmspe:0.009525\n",
      "[33]\teval-rmspe:0.008807\ttrain-rmspe:0.009164\n",
      "[34]\teval-rmspe:0.008395\ttrain-rmspe:0.008765\n",
      "[35]\teval-rmspe:0.007951\ttrain-rmspe:0.008254\n",
      "[36]\teval-rmspe:0.007578\ttrain-rmspe:0.007907\n",
      "[37]\teval-rmspe:0.007258\ttrain-rmspe:0.007549\n",
      "[38]\teval-rmspe:0.006865\ttrain-rmspe:0.007185\n",
      "[39]\teval-rmspe:0.006481\ttrain-rmspe:0.006826\n",
      "[40]\teval-rmspe:0.006215\ttrain-rmspe:0.006579\n",
      "[41]\teval-rmspe:0.005907\ttrain-rmspe:0.006257\n",
      "[42]\teval-rmspe:0.005756\ttrain-rmspe:0.006137\n",
      "[43]\teval-rmspe:0.005374\ttrain-rmspe:0.005731\n",
      "[44]\teval-rmspe:0.005070\ttrain-rmspe:0.005437\n",
      "[45]\teval-rmspe:0.004863\ttrain-rmspe:0.005239\n",
      "[46]\teval-rmspe:0.004679\ttrain-rmspe:0.005071\n",
      "[47]\teval-rmspe:0.004555\ttrain-rmspe:0.004913\n",
      "[48]\teval-rmspe:0.004440\ttrain-rmspe:0.004804\n",
      "[49]\teval-rmspe:0.004090\ttrain-rmspe:0.004436\n",
      "[50]\teval-rmspe:0.004047\ttrain-rmspe:0.004364\n",
      "[51]\teval-rmspe:0.003871\ttrain-rmspe:0.004209\n",
      "[52]\teval-rmspe:0.003347\ttrain-rmspe:0.003832\n",
      "[53]\teval-rmspe:0.003622\ttrain-rmspe:0.003670\n",
      "[54]\teval-rmspe:0.003465\ttrain-rmspe:0.003523\n",
      "[55]\teval-rmspe:0.003360\ttrain-rmspe:0.003447\n",
      "[56]\teval-rmspe:0.003189\ttrain-rmspe:0.003282\n",
      "[57]\teval-rmspe:0.003150\ttrain-rmspe:0.003252\n",
      "[58]\teval-rmspe:0.003157\ttrain-rmspe:0.003276\n",
      "[59]\teval-rmspe:0.003130\ttrain-rmspe:0.003265\n",
      "[60]\teval-rmspe:0.003123\ttrain-rmspe:0.003291\n",
      "[61]\teval-rmspe:0.002930\ttrain-rmspe:0.003107\n",
      "[62]\teval-rmspe:0.002868\ttrain-rmspe:0.003075\n",
      "[63]\teval-rmspe:0.002810\ttrain-rmspe:0.003016\n",
      "[64]\teval-rmspe:0.002662\ttrain-rmspe:0.002889\n",
      "[65]\teval-rmspe:0.002597\ttrain-rmspe:0.002849\n",
      "[66]\teval-rmspe:0.002525\ttrain-rmspe:0.002797\n",
      "[67]\teval-rmspe:0.002462\ttrain-rmspe:0.002749\n",
      "[68]\teval-rmspe:0.002307\ttrain-rmspe:0.002652\n",
      "[69]\teval-rmspe:0.002178\ttrain-rmspe:0.002540\n",
      "[70]\teval-rmspe:0.002037\ttrain-rmspe:0.002387\n",
      "[71]\teval-rmspe:0.002001\ttrain-rmspe:0.002370\n",
      "[72]\teval-rmspe:0.001968\ttrain-rmspe:0.002346\n",
      "[73]\teval-rmspe:0.001868\ttrain-rmspe:0.002270\n",
      "[74]\teval-rmspe:0.001782\ttrain-rmspe:0.002207\n",
      "[75]\teval-rmspe:0.001743\ttrain-rmspe:0.002203\n",
      "[76]\teval-rmspe:0.001718\ttrain-rmspe:0.002199\n",
      "[77]\teval-rmspe:0.001658\ttrain-rmspe:0.002129\n",
      "[78]\teval-rmspe:0.001586\ttrain-rmspe:0.002078\n",
      "[79]\teval-rmspe:0.001514\ttrain-rmspe:0.002024\n",
      "[80]\teval-rmspe:0.001486\ttrain-rmspe:0.002002\n",
      "[81]\teval-rmspe:0.001439\ttrain-rmspe:0.001968\n",
      "[82]\teval-rmspe:0.001429\ttrain-rmspe:0.001969\n",
      "[83]\teval-rmspe:0.001237\ttrain-rmspe:0.001776\n",
      "[84]\teval-rmspe:0.001260\ttrain-rmspe:0.001807\n",
      "[85]\teval-rmspe:0.001255\ttrain-rmspe:0.001829\n",
      "[86]\teval-rmspe:0.001255\ttrain-rmspe:0.001844\n",
      "[87]\teval-rmspe:0.001227\ttrain-rmspe:0.001832\n",
      "[88]\teval-rmspe:0.001122\ttrain-rmspe:0.001728\n",
      "[89]\teval-rmspe:0.001113\ttrain-rmspe:0.001724\n",
      "[90]\teval-rmspe:0.001063\ttrain-rmspe:0.001692\n",
      "[91]\teval-rmspe:0.001024\ttrain-rmspe:0.001662\n",
      "[92]\teval-rmspe:0.000976\ttrain-rmspe:0.001631\n",
      "[93]\teval-rmspe:0.000931\ttrain-rmspe:0.001592\n",
      "[94]\teval-rmspe:0.000944\ttrain-rmspe:0.001608\n",
      "[95]\teval-rmspe:0.000897\ttrain-rmspe:0.001587\n",
      "[96]\teval-rmspe:0.000888\ttrain-rmspe:0.001567\n",
      "[97]\teval-rmspe:0.000882\ttrain-rmspe:0.001507\n",
      "[98]\teval-rmspe:0.000852\ttrain-rmspe:0.001495\n",
      "[99]\teval-rmspe:0.000804\ttrain-rmspe:0.001494\n",
      "[100]\teval-rmspe:0.000755\ttrain-rmspe:0.001440\n",
      "[101]\teval-rmspe:0.000743\ttrain-rmspe:0.001381\n",
      "[102]\teval-rmspe:0.000741\ttrain-rmspe:0.001363\n",
      "[103]\teval-rmspe:0.000714\ttrain-rmspe:0.001330\n",
      "[104]\teval-rmspe:0.000684\ttrain-rmspe:0.001325\n",
      "[105]\teval-rmspe:0.000651\ttrain-rmspe:0.001294\n",
      "[106]\teval-rmspe:0.000560\ttrain-rmspe:0.001211\n",
      "[107]\teval-rmspe:0.000569\ttrain-rmspe:0.001242\n",
      "[108]\teval-rmspe:0.000671\ttrain-rmspe:0.001228\n",
      "[109]\teval-rmspe:0.000667\ttrain-rmspe:0.001233\n",
      "[110]\teval-rmspe:0.000730\ttrain-rmspe:0.001243\n",
      "[111]\teval-rmspe:0.000693\ttrain-rmspe:0.001210\n",
      "[112]\teval-rmspe:0.000676\ttrain-rmspe:0.001208\n",
      "[113]\teval-rmspe:0.000784\ttrain-rmspe:0.001214\n",
      "[114]\teval-rmspe:0.000780\ttrain-rmspe:0.001214\n",
      "[115]\teval-rmspe:0.000740\ttrain-rmspe:0.001184\n",
      "[116]\teval-rmspe:0.001476\ttrain-rmspe:0.001192\n",
      "[117]\teval-rmspe:0.001455\ttrain-rmspe:0.001191\n",
      "[118]\teval-rmspe:0.001417\ttrain-rmspe:0.001177\n",
      "[119]\teval-rmspe:0.001481\ttrain-rmspe:0.001137\n",
      "[120]\teval-rmspe:0.001303\ttrain-rmspe:0.001144\n",
      "[121]\teval-rmspe:0.001274\ttrain-rmspe:0.001125\n",
      "[122]\teval-rmspe:0.001332\ttrain-rmspe:0.001129\n",
      "[123]\teval-rmspe:0.001323\ttrain-rmspe:0.001160\n",
      "[124]\teval-rmspe:0.001234\ttrain-rmspe:0.001150\n",
      "[125]\teval-rmspe:0.001039\ttrain-rmspe:0.001110\n",
      "[126]\teval-rmspe:0.001048\ttrain-rmspe:0.001110\n",
      "[127]\teval-rmspe:0.001040\ttrain-rmspe:0.001115\n",
      "[128]\teval-rmspe:0.001359\ttrain-rmspe:0.001110\n",
      "[129]\teval-rmspe:0.001424\ttrain-rmspe:0.001140\n",
      "[130]\teval-rmspe:0.001429\ttrain-rmspe:0.001136\n",
      "[131]\teval-rmspe:0.001398\ttrain-rmspe:0.001131\n",
      "[132]\teval-rmspe:0.001433\ttrain-rmspe:0.001160\n",
      "[133]\teval-rmspe:0.001233\ttrain-rmspe:0.001169\n",
      "[134]\teval-rmspe:0.001262\ttrain-rmspe:0.001159\n",
      "[135]\teval-rmspe:0.001290\ttrain-rmspe:0.001167\n",
      "[136]\teval-rmspe:0.001609\ttrain-rmspe:0.001149\n",
      "[137]\teval-rmspe:0.001522\ttrain-rmspe:0.001171\n",
      "[138]\teval-rmspe:0.001435\ttrain-rmspe:0.001179\n",
      "[139]\teval-rmspe:0.001598\ttrain-rmspe:0.001189\n",
      "[140]\teval-rmspe:0.001575\ttrain-rmspe:0.001168\n",
      "[141]\teval-rmspe:0.001557\ttrain-rmspe:0.001147\n",
      "[142]\teval-rmspe:0.001638\ttrain-rmspe:0.001153\n",
      "[143]\teval-rmspe:0.001267\ttrain-rmspe:0.001113\n",
      "[144]\teval-rmspe:0.002140\ttrain-rmspe:0.001089\n",
      "[145]\teval-rmspe:0.002162\ttrain-rmspe:0.001097\n",
      "[146]\teval-rmspe:0.002152\ttrain-rmspe:0.001089\n",
      "[147]\teval-rmspe:0.002202\ttrain-rmspe:0.001068\n",
      "[148]\teval-rmspe:0.000461\ttrain-rmspe:0.001060\n",
      "[149]\teval-rmspe:0.000454\ttrain-rmspe:0.001063\n",
      "[150]\teval-rmspe:0.000441\ttrain-rmspe:0.001051\n",
      "[151]\teval-rmspe:0.000425\ttrain-rmspe:0.001036\n",
      "[152]\teval-rmspe:0.000327\ttrain-rmspe:0.000994\n",
      "[153]\teval-rmspe:0.000299\ttrain-rmspe:0.000988\n",
      "[154]\teval-rmspe:0.000313\ttrain-rmspe:0.000996\n",
      "[155]\teval-rmspe:0.000296\ttrain-rmspe:0.001014\n",
      "[156]\teval-rmspe:0.000257\ttrain-rmspe:0.000976\n",
      "[157]\teval-rmspe:0.000256\ttrain-rmspe:0.000976\n",
      "[158]\teval-rmspe:0.000282\ttrain-rmspe:0.000972\n",
      "[159]\teval-rmspe:0.000281\ttrain-rmspe:0.000976\n",
      "[160]\teval-rmspe:0.000253\ttrain-rmspe:0.000961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 0.0143505495191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping. Best iteration:\n",
      "[10]\teval-rmspe:0.000558\ttrain-rmspe:0.000249\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bst = fit_xgb(X_tr, X_te, y_tr, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store 0.255037463271\n",
      "DayOfWeek 0.0619847931429\n",
      "Promo 0.135162833191\n",
      "StateHoliday 0.00331530166946\n",
      "SchoolHoliday 0.00552852774546\n",
      "StoreType 0.0496856790686\n",
      "Assortment 0.0209541175677\n",
      "CompetitionDistance 0.251464786535\n",
      "Promo2 0.00521432965735\n",
      "DayOfYear 0.0656543783601\n",
      "Month 0.00682628585218\n",
      "CompetitionOpen 0.104620480348\n",
      "Meta 0.0345510235913\n",
      "Error 0.0210864899866\n"
     ]
    }
   ],
   "source": [
    "#importance of features\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "clf = RandomForestRegressor(n_jobs=-1, random_state=10, n_estimators = 100)\n",
    "  \n",
    "clf.fit(X_tr, y_tr)\n",
    "\n",
    "predicted = clf.predict(X_te)\n",
    "    \n",
    "imp = clf.feature_importances_\n",
    "    \n",
    "for i in xrange(len(cols)):\n",
    "    \n",
    "    print cols[i], imp[i]\n",
    "    \n",
    "print 'Error', np.fabs(rmspe(y_te, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0218817547286\n"
     ]
    }
   ],
   "source": [
    "#cross_validation on RandomForest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "clf = RandomForestRegressor(n_jobs=-1, random_state=10, n_estimators = 100)\n",
    "\n",
    "scores = cross_val_score(clf, X_tr, y_tr, cv=5, scoring=rmspe_scorer)\n",
    "\n",
    "print np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = bst.predict(xgboost.DMatrix(test))\n",
    "test_df['predicted'] = (predicted * test_df['Open']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df['predicted'].to_csv('output.csv', index=False, index_label=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
