{
 "metadata": {
  "language": "Julia",
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "|   \t| Regression Model \t| Reason for selection \t| Results of application on the dataset  \t|\n",
      "|---\t|------------------\t|----------------------\t|---\t|\n",
      "|  1 \t| Weigted Linear Regression                 \t| Selected as a standard model for regression and analyzing the p and t values.                     \t| This model has been applied on all the datasets for the purpose of feature selection, analysis of the condition indexes.  \t|\n",
      "| 2  \t|  Linear Regression Model                 \t| This is a simple regression model for developing a predictive model for the data with very less or zero multi-collinearity. The presence of collinearity makes the inversion of the feature matrix more and more difficult.                     \t| This model proved effective in the case of datasets 1 and 3. These datasets have a very similar interaction between their variables. Their respective plots support this fact. So, after the removal of the features which contribute to multi-collinearity and also with a very less (<0.05) p-value, the linear regression model is fitted. \t|\n",
      "| 3  \t| KNN Regression                 \t| The more uniform the spread of data in the higher dimensional space, the better the performance of the KNN algorithm. So, the model fitted the datasets 2 and 5 well. But, even the KNN model should be fitted on the data after the feature selection process is done.  <b>This is because, if two or more variable are collinear, the distance between them in the higher dimensional space, would be very less, which would result in a failure for the KNN algorithm.  </b>                    \t| This is applied to the datasets 2 and 5 after the linear regression model is applied, as an improvement. As it is clearly evident from the datasets 2 and 5 that they have high and uniform spread, the KNN model can be used as a predictive model. <br> <b> An important observation :-</b> </br>  The dataset 5 has a very uniform, discrete numeric data. So, KNN would be an excellent idea for the predictive model of such data, due to the uniformity of the distances between the data points.\t|\n",
      "|4\t|Lasso Regression Model\t| This model is used in the analysis just to make sure that my feature selection procedure is going right. As Lasso shrinks the coefficients, such that they all constitute a sparse matrix after shrinkage, so the selection of features from the resulting matrix would become easy.\t| Same as the linear regression, after feature selection.\t|"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h2>Approach towards the datasets 4 and 5.</h2>\n",
      "<p> When the pairs plot of the dataset-5 is analyzed, it can be infered straight-away that the variables are correlated and are also discrete, with an even spread(uniform). So, as the distances between the two succesive points follow a particular sequence or progression, the KNN approach would be best suited as a predictive model.\n",
      "So, as the information is given that the dataset-4 also have a similar relationship among it's variables, we can extend our model to this dataset too. </p>\n",
      "<br></br>\n",
      "<h2>Approach towards the datasets 1,2 and 3</h2>\n",
      "<p> From the analysis of dataset 1, we can infer that after removing the variables which have a high p-value, a linear model can be fitted on the resulting training set. The elimination of those features also simultaneously, reduce the condition indexes(collinearity measure), so that we don't have the collinearity scare, while fitting a linear regression model through our training set.</p>\n",
      "<p>And fairly enough, the analyses of the datasets 2 and 3 have been very similar to the work-flow (eliminate the least influential features, and set a linear regression model) followed for the dataset1, thus supporting the given information</p>\n",
      "<h2>Using the given information for faster analyses</h2>\n",
      "<p>By using the information, the analyses can be done faster, as the relationship between the variables aer known, so the model is also chosen   accordingly. (Ex: KNN for a well-spaced, discrete, evenly spread data, and linear regression for a feature-selected collinearity free-data, so directly applying the model and then moving on to the cross-vallidation of the model for optimization(gradient-descent  for lin. reg. and selection of \"k\" in KNN), takes less time than before.)</p>"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}
